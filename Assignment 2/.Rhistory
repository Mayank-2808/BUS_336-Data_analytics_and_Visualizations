library(mosaic)
library(formatR)
library(leaps)
library(dplyr)
# Load the data
data <- read.csv('./Honda_Sales.csv')
# Splitting the data into training and testing sets
train_data <- data %>% filter(Year <= 12)
test_data <- data %>% filter(Year >= 13)
# Calculating the percentages
total_size <- nrow(data)
train_size <- nrow(train_data)
test_size <- nrow(test_data)
train_per <- (train_size / total_size) * 100
test_per <- (test_size / total_size) * 100
# Printing the percentages
print(paste("Training data percentage:", train_per, "%"))
print(paste("Testing data percentage:", test_per, "%"))
# Saving the training data to a CSV file
write.csv(train_data, 'Honda_Sales_Training.csv', row.names = FALSE)
#Building model1
model1 <- lm(Sales ~ Unemployment + CPI_All + CPI_Energy + Queries, data = train_data)
summary(model1)
# model1 R-squared value
model1_r2 <- summary(model1)$r.squared
model1_r2
# Getting significant variables
model1_sig_vars <- summary(model1)$coefficients[,4] < 0.10  # 90% confidence interval
model1_sig_vars
# Building model2
model2 <- lm(Sales ~ Unemployment + CPI_All + CPI_Energy + Queries + Year + Month, data = train_data)
summary(model2)
# model2 R-squared value
model2_r2 <- summary(model2)$r.squared
model2_r2
# Getting significant variables
model2_sig_vars <- summary(model2)$coefficients[,4] < 0.10  # 90% confidence interval
model2_sig_vars
# Converting Month to a factor variable
train_data$Month_Factor <- as.factor(train_data$Month)
test_data$Month_Factor <- as.factor(test_data$Month)
# Building model3
model3 <- lm(Sales ~ Unemployment + CPI_All + CPI_Energy + Queries + Year + Month_Factor, data = train_data)
summary(model3)
# model3 R-squared value
model3_r2 <- summary(model3)$r.squared
model3_r2
# Applying step-wise elimination to model3
best_model <- step(model3)
summary(best_model)
# best_model R-squared value
best_model_r2 <- summary(model3)$r.squared
best_model_r2
# Finding removed variables
removed_vars <- setdiff(names(coef(model3)), names(coef(best_model)))
removed_vars
# Regression equation for best model
best_model_eq <- formula(best_model)
best_model_eq
# making predictions
predict_train <- predict(best_model, newdata = train_data)
train_data$PredictTrain <- predict_train
library(Metrics)
# Calculating RMSE, MAE, and MAPE for the training dataset
rmse_value <- rmse(train_data$Sales, train_data$PredictTrain)
print(paste("RMSE value:", rmse_value))
mae_value <- mae(train_data$Sales, train_data$PredictTrain)
print(paste("MAE value:", mae_value))
mape_value <- mape(train_data$Sales, train_data$PredictTrain)
print(paste("MAPE value:", mape_value))
write.csv(predict_train, 'predict_train.csv', row.names = TRUE)
# Making predictions on testing data
predict_test <- predict(best_model, newdata = test_data)
test_data$PredictTest <- predict_test
# Saving testing data in 'testing_data.csv'
write.csv(test_data, "testing_data.csv")
# Saving predicted data
write.csv(predict_test, 'predict_test.csv', row.names = TRUE)
# Calculating RMSE, MAE, and MAPE for the testing dataset
rmse_value <- rmse(test_data$Sales, predict_test)
print(paste("RMSE value:", rmse_value))
mae_value <- mae(test_data$Sales, predict_test)
print(paste("MAE value:", mae_value))
mape_value <- mape(test_data$Sales, predict_test)
print(paste("MAPE value:", mape_value))
